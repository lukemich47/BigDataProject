{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This will scrape Riyadh-local Twitter data over time\n",
    "\n",
    "#import libraries and personal twitter API key\n",
    "import twython\n",
    "import json\n",
    "import time\n",
    "import threading\n",
    "\n",
    "from datetime import datetime\n",
    "from twython import Twython\n",
    "\n",
    "from twitter_key import t_key, t_secret\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assigns the keys to the variables\n",
    "APP_KEY = t_key\n",
    "APP_SECRET = t_secret\n",
    "\n",
    "# Fetches tweets with a given query at a given lat-long.\n",
    "def get_tweets( latlong=None ):\n",
    "    # Creates a Twython object with the given keys\n",
    "    twitter = Twython( APP_KEY, APP_SECRET )\n",
    "    # Uses the search function to hit the APIs endpoints and look for recent tweets within the area\n",
    "    results = twitter.search( geocode=','.join([ str(x) for x in latlong ]) + ',15km', result_type='recent', count=10000)\n",
    "    # Returns the only the statuses from the resulting JSON\n",
    "    return results['statuses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repeated collecting of tweets\n",
    "def get_lots_of_tweets( latlong ):\n",
    "    # Create a dictionary to parse the JSON\n",
    "    all_tweets = {}\n",
    "    \n",
    "    # We will be hitting the API a number of times within the total time\n",
    "    total_time = 120\n",
    "    # Everytime we hit the API we subtract time from the total\n",
    "    remaining_seconds = total_time\n",
    "    interval = 30 \n",
    "    while remaining_seconds > 0:\n",
    "        added = 0\n",
    "        # We hit the Twitter API\n",
    "        new_tweets = get_tweets( latlong )\n",
    "        # We parse the resulting JSON, and save the rest of the raw content\n",
    "        for tweet in new_tweets:\n",
    "            tid = tweet['id']\n",
    "            if tid not in all_tweets and tweet['coordinates'] != None:\n",
    "                properties = {}\n",
    "                properties['lat'] = tweet['coordinates']['coordinates'][0]\n",
    "                properties['lon'] = tweet['coordinates']['coordinates'][1]\n",
    "                properties['tweet_id'] = tid\n",
    "                properties['content'] = tweet['text']\n",
    "                properties['user'] = tweet['user']['id']\n",
    "                properties['user_location'] = tweet['user']['location']\n",
    "                properties['raw_source'] = tweet\n",
    "                properties['data_point'] = 'none'\n",
    "                properties['time'] = tweet['created_at']\n",
    "                all_tweets[ tid ] = properties\n",
    "                added += 1\n",
    "        print \"At %d seconds, added %d new tweets, for a total of %d\" % ( total_time - remaining_seconds, added, len( all_tweets ) )\n",
    "        # We wait a few seconds and hit the API again\n",
    "        time.sleep(interval)\n",
    "        remaining_seconds -= interval\n",
    "    # We return the final dictionary\n",
    "    return all_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''This function executes the rest of the functions over a given period of time'''\n",
    "def run():\n",
    "    # This is the number of times the code will be executed. In this case, just once. \n",
    "    starting = 1\n",
    "    while starting > 0:\n",
    "        # Sometimes the API returns some errors, killing the whole script, so we setup try/except to make sure it keeps running\n",
    "        try:\n",
    "            # We define a centroid in Riyadh\n",
    "            latlong = [24.6333, 46.7167]\n",
    "            t = get_lots_of_tweets( latlong )\n",
    "            # We name every file with the current time\n",
    "            timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "            # We write a new JSON into the target path\n",
    "            with open( 'twitter\\%stweets.json' %(timestr), 'w' ) as f:\n",
    "                f.write( json.dumps(t))\n",
    "            # we can use a library like threading to execute the run function continuously.\n",
    "            #threading.Timer(10, run).start()\n",
    "            starting -= 1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "run()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
